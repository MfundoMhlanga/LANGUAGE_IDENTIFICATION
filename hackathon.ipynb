{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d9d2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "import re\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "#import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline \n",
    "\n",
    "# Import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv(\"train_set.csv\")\n",
    "test = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28eea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bd7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at the information of the train dataset\n",
    "print(\"looking at the information of the train dataset\")\n",
    "train.info()\n",
    "print(\"looking at the shape of the train dataset\")\n",
    "#looking at the shape of the train dataset\n",
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05097201",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are', len(train), 'rows and',train.shape[1], 'columns in the train set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fda64056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang_id    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cheking for null values\n",
    "train.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e8d1fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ven    3000\n",
       "ssw    3000\n",
       "sot    3000\n",
       "eng    3000\n",
       "afr    3000\n",
       "zul    3000\n",
       "tsn    3000\n",
       "tso    3000\n",
       "nso    3000\n",
       "xho    3000\n",
       "nbl    3000\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the total number of each observation in the train data\n",
    "train['lang_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35def068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tsn</td>\n",
       "      <td>fa le dirisiwa lebone le tshwanetse go bontsha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nbl</td>\n",
       "      <td>lapho inarha yangeqadi ingenwe ngokungasimthet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zul</td>\n",
       "      <td>i-tip-offs anonymous wusizo locingo oluzimele ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nbl</td>\n",
       "      <td>isitifikhethi somtjhado esingakarhunyezwa namk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32980</th>\n",
       "      <td>ssw</td>\n",
       "      <td>inhloso ye-wua kutsi yente bantfu bendzawo let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32983</th>\n",
       "      <td>ssw</td>\n",
       "      <td>timiso tesigatjana titawusebenta ngetingucuko ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32985</th>\n",
       "      <td>nso</td>\n",
       "      <td>ge o nyaka go kgopela phihlelelo ya direkoto t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32989</th>\n",
       "      <td>ssw</td>\n",
       "      <td>imenenja yesigodzi utakwatisa ngembhalo uma le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>sot</td>\n",
       "      <td>modise mosadi na o ntse o sa utlwe hore thaban...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5599 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id                                               text\n",
       "0         xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "9         tsn  fa le dirisiwa lebone le tshwanetse go bontsha...\n",
       "10        nbl  lapho inarha yangeqadi ingenwe ngokungasimthet...\n",
       "12        zul  i-tip-offs anonymous wusizo locingo oluzimele ...\n",
       "19        nbl  isitifikhethi somtjhado esingakarhunyezwa namk...\n",
       "...       ...                                                ...\n",
       "32980     ssw  inhloso ye-wua kutsi yente bantfu bendzawo let...\n",
       "32983     ssw  timiso tesigatjana titawusebenta ngetingucuko ...\n",
       "32985     nso  ge o nyaka go kgopela phihlelelo ya direkoto t...\n",
       "32989     ssw  imenenja yesigodzi utakwatisa ngembhalo uma le...\n",
       "32996     sot  modise mosadi na o ntse o sa utlwe hore thaban...\n",
       "\n",
       "[5599 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking duplicates\n",
    "txt = train['text']\n",
    "#sg= df_train['message']\n",
    "train[txt.isin(txt[txt.duplicated()])]\n",
    "#rain[msg.isin(msg[msg.duplicated()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7914516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nso</td>\n",
       "      <td>dinyakišišo tše tša go dirwa gabedi ka ngwaga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32994</th>\n",
       "      <td>eng</td>\n",
       "      <td>manuel marin s ill-fated debt sources but very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>tsn</td>\n",
       "      <td>popo ya dipolateforomo tse ke go tlisa boetele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>eng</td>\n",
       "      <td>closing date for the submission of completed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>xho</td>\n",
       "      <td>nawuphina umntu ofunyenwe enetyala phantsi kwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>sot</td>\n",
       "      <td>mafapha a mang le ona a lokela ho etsa ditlale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27401 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id                                               text\n",
       "1         xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2         eng  the province of kwazulu-natal department of tr...\n",
       "3         nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4         ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "5         nso  dinyakišišo tše tša go dirwa gabedi ka ngwaga ...\n",
       "...       ...                                                ...\n",
       "32994     eng  manuel marin s ill-fated debt sources but very...\n",
       "32995     tsn  popo ya dipolateforomo tse ke go tlisa boetele...\n",
       "32997     eng  closing date for the submission of completed t...\n",
       "32998     xho  nawuphina umntu ofunyenwe enetyala phantsi kwa...\n",
       "32999     sot  mafapha a mang le ona a lokela ho etsa ditlale...\n",
       "\n",
       "[27401 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing duplicates\n",
    "train.drop_duplicates(subset = \"text\",keep = False,inplace = True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6e1192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models\n",
    "names = ['Logistic Regression','Random Forest', 'Nearest Neighbors', \n",
    "         'Decision Tree','MultinomialNB','Linear SVC', 'XG Boost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1497837d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultinomialNB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a1700ffe3da0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                       \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                       ngram_range = (1,2))),\n\u001b[0;32m---> 27\u001b[0;31m              ('clf', MultinomialNB())]),\n\u001b[0m\u001b[1;32m     28\u001b[0m     Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n\u001b[1;32m     29\u001b[0m                                       \u001b[0msmooth_idf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MultinomialNB' is not defined"
     ]
    }
   ],
   "source": [
    "# List of classifiers\n",
    "classifiers = [\n",
    "    Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', LogisticRegression())]),\n",
    "    Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', RandomForestClassifier())]),\n",
    "    Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', KNeighborsClassifier())]),\n",
    "    Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', DecisionTreeClassifier())]),\n",
    "    Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', MultinomialNB())]),\n",
    "    Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', LinearSVC())]),\n",
    "        Pipeline([('tfid', TfidfVectorizer(max_df = 0.4,\n",
    "                                      smooth_idf = True,\n",
    "                                      stop_words = 'english',\n",
    "                                      ngram_range = (1,2))),\n",
    "             ('clf', XGBClassifier())])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6539194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['lang_id']\n",
    "X = train['text']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 10) #Splitting the datat into training nd testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fe25c36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifiers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b25b05e1dfcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting {:s} model...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrun_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-q -o clf.fit(X_train, y_train) #Training the model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifiers' is not defined"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "models = {}\n",
    "confusion = {}\n",
    "class_report = {}\n",
    "\n",
    "\n",
    "for name, clf in zip(names, classifiers):    \n",
    "    print ('Fitting {:s} model...'.format(name))\n",
    "    run_time = %timeit -q -o clf.fit(X_train, y_train) #Training the model\n",
    "    \n",
    "    print ('... predicting')\n",
    "    y_pred = clf.predict(X_train)   \n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    models[name] = clf #storing the trained models in the models dictionary    \n",
    "    \n",
    "    results.append([name, run_time.best]) \n",
    "\n",
    "    \n",
    "results = pd.DataFrame(results, columns=['Classifier', 'Train Time'])\n",
    "results.set_index('Classifier', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a60252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Logistic Regresion\n",
    "# lr = models['Logistic Regression']\n",
    "# t = test['text']\n",
    "# y_pred_lr = lr.predict(t)\n",
    "# sub = pd.DataFrame( data = {'index': test['index'],\n",
    "#                              'lang_id': y_pred_lr })\n",
    "# sub.to_csv('submission_lr2.csv', index = False)\n",
    "\n",
    "#Random forest\n",
    "rf = models['Random Forest']\n",
    "y_pred_rf = rf.predict(t)\n",
    "sub = pd.DataFrame( data = {'index': test['index'],\n",
    "                             'lang_id': y_pred_rf })\n",
    "sub.to_csv('submission_fr.csv', index = False)\n",
    "\n",
    "# #Nearest Neighbors\n",
    "# nn = models['Nearest Neighbors']\n",
    "# y_pred_nn = nn.predict(t)\n",
    "# sub = pd.DataFrame( data = {'index': test['index'],\n",
    "#                              'lang_id': y_pred_nn })\n",
    "# sub.to_csv('submission_nn.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c30c847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    }
   ],
   "source": [
    "# Logistic\n",
    "tfid = TfidfVectorizer()\n",
    "text = tfid.fit_transform(train['text'])\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(text,y, test_size = 0.2, random_state = 10)\n",
    "n_estimators = [10, 100, 1000, 2000]\n",
    "max_depth = [None, 5, 10, 20]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=10)\n",
    "\n",
    "# search the grid\n",
    "grid = GridSearchCV(estimator=rf, \n",
    "                    param_grid=param_grid,\n",
    "                    cv=2,\n",
    "                    verbose=2,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train_h, y_train_h)\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa25fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
